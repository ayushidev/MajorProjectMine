{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "\n",
       "   domain1_score  \n",
       "0      66.666667  \n",
       "1      75.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('test.xlsx')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:47: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:50: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:54: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:57: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:60: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:63: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:68: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:69: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:70: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:71: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:72: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:73: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "num_rows = df.shape[0]\n",
    "essays = df['essay'].values\n",
    "\n",
    "#Initialize dataframe columns\n",
    "df['word_count'] = np.nan \n",
    "df['sentence_count'] = np.nan\n",
    "df['avg_word_length'] = np.nan \n",
    "df['num_exclamation_marks'] = np.nan\n",
    "df['num_question_marks'] = np.nan\n",
    "df['num_stopwords'] = np.nan\n",
    "\n",
    "df['noun_count'] = np.nan\n",
    "df['verb_count'] = np.nan\n",
    "df['foreign_count'] = np.nan\n",
    "df['adj_count'] = np.nan\n",
    "df['conj_count'] = np.nan\n",
    "df['adv_count'] = np.nan\n",
    "\n",
    "def get_pos_tags(essay):\n",
    "    nouns = verbs = foreign = adj = adv = conj = 0\n",
    "    tokens = nltk.word_tokenize(essay)\n",
    "    for token in tokens:\n",
    "        pos_tag = nltk.pos_tag(nltk.word_tokenize(token))\n",
    "        for (_, tag) in (pos_tag):\n",
    "            if tag[0] == \"N\":\n",
    "                nouns += 1\n",
    "            elif tag[0] == \"V\":\n",
    "                verbs += 1\n",
    "            elif tag[0:2] == \"FW\":\n",
    "                foreign += 1\n",
    "            elif tag[0] == \"J\":\n",
    "                adj += 1\n",
    "            elif tag[0] == \"R\":\n",
    "                adv += 1\n",
    "            elif tag[0:2] == \"CC\" or tag[0:2] == \"IN\":\n",
    "                conj += 1\n",
    "    \n",
    "    return [nouns, verbs, foreign, adj, adv, conj]\n",
    "\n",
    "\n",
    "for i in range(num_rows):\n",
    "    \n",
    "    # Turn essay into list of words\n",
    "    text = essays[i].split(\" \")\n",
    "    \n",
    "    # Set word count\n",
    "    df.set_value(i,'word_count', len(text))\n",
    "    \n",
    "    # Sentence count\n",
    "    df.set_value(i, 'sentence_count', len(nltk.tokenize.sent_tokenize(essays[i])))\n",
    "    \n",
    "    # Average word length\n",
    "    word_len = sum(len(word) for word in text) / len(text)\n",
    "    df.set_value(i, 'avg_word_length', word_len)\n",
    "    \n",
    "    # Number of exclamation marks\n",
    "    df.set_value(i, \"num_exclamation_marks\", sum(word.count(\"!\") for word in essays[i]))\n",
    "    \n",
    "    # Number of question marks\n",
    "    df.set_value(i, \"num_question_marks\", sum(word.count(\"?\") for word in essays[i]))\n",
    "    \n",
    "    # Number of stop words\n",
    "    df.set_value(i, \"num_stopwords\", sum([1 for word in text if word.lower() in stopwords]))\n",
    "\n",
    "    \n",
    "    # POS tag counts\n",
    "    pos_lst = get_pos_tags(essays[i])\n",
    "    df.set_value(i,'noun_count', pos_lst[0])\n",
    "    df.set_value(i,'verb_count', pos_lst[1])\n",
    "    df.set_value(i,'foreign_count', pos_lst[2])\n",
    "    df.set_value(i,'adj_count', pos_lst[3])\n",
    "    df.set_value(i,'adv_count', pos_lst[4])\n",
    "    df.set_value(i,'conj_count', pos_lst[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def avg_sentence_sentiment(x):\n",
    "    sentiment_essay = TextBlob(x).sentiment.polarity\n",
    "    return sentiment_essay\n",
    "df['sentiment_essay'] = df['essay'].apply(avg_sentence_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_check\n",
    "def grammar_check(x):\n",
    "    tool = language_check.LanguageTool('en-US')\n",
    "    matches = tool.check(x)\n",
    "    return len(matches)\n",
    "df['Grammar_check'] = df['essay'].apply(grammar_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>num_exclamation_marks</th>\n",
       "      <th>num_question_marks</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>foreign_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>conj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>sentiment_essay</th>\n",
       "      <th>grade</th>\n",
       "      <th>grades</th>\n",
       "      <th>Grammar_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>338.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.550296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.310471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>419.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.463007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>279.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.526882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.340393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>524.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.041985</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.266828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>465.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.526882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.199684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  word_count  sentence_count  avg_word_length  \\\n",
       "0      66.666667       338.0            16.0         4.550296   \n",
       "1      75.000000       419.0            20.0         4.463007   \n",
       "2      58.333333       279.0            14.0         4.526882   \n",
       "3      83.333333       524.0            27.0         5.041985   \n",
       "4      66.666667       465.0            30.0         4.526882   \n",
       "\n",
       "   num_exclamation_marks  num_question_marks  num_stopwords  noun_count  \\\n",
       "0                    4.0                 2.0          168.0       120.0   \n",
       "1                    1.0                 1.0          189.0       148.0   \n",
       "2                    0.0                 0.0          140.0       110.0   \n",
       "3                    2.0                 1.0          222.0       263.0   \n",
       "4                    0.0                 0.0          236.0       150.0   \n",
       "\n",
       "   verb_count  foreign_count  adj_count  conj_count  adv_count  \\\n",
       "0        39.0            0.0       13.0        69.0       22.0   \n",
       "1        56.0            0.0       14.0        80.0       21.0   \n",
       "2        33.0            0.0       13.0        50.0       17.0   \n",
       "3        57.0            0.0       29.0        84.0       30.0   \n",
       "4        60.0            0.0       18.0        63.0       41.0   \n",
       "\n",
       "   sentiment_essay  grade  grades  Grammar_check  \n",
       "0         0.310471    NaN     NaN             11  \n",
       "1         0.274000    NaN     NaN             19  \n",
       "2         0.340393    NaN     NaN              9  \n",
       "3         0.266828    NaN     NaN             35  \n",
       "4         0.199684    NaN     NaN             17  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['domain1_score', 'essay','essay_id','essay_set'], axis=1)\n",
    "# y = df['domain1_score']\n",
    "\n",
    "# x = df_normalized.drop(['domain1_score'],axis=1)\n",
    "# # df['A']=df['A'].fillna(0.0).astype(int)\n",
    "y = df['domain1_score'].fillna(0.0).astype(int)\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "where_are_NaNs = np.isnan(x)\n",
    "x[where_are_NaNs] = 0\n",
    "where_are_NaNs = np.isnan(y)\n",
    "y[where_are_NaNs] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "for train_index, test_index in kfold.split(x, y):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "logistic_reg = LogisticRegression()\n",
    "logistic_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression classifier accuracy: 0.31805825242718444\n"
     ]
    }
   ],
   "source": [
    "predictions = logistic_reg.predict(X_test)\n",
    "print('Logistic regression classifier accuracy:', logistic_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "for train_index, test_index in kfold.split(x, y):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression classifier accuracy: 0.22916389130549164\n"
     ]
    }
   ],
   "source": [
    "predictions = lin_reg.predict(X_test)\n",
    "print('Linear regression classifier accuracy:', lin_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (linear) Regressor Accuracy: 0.21532152291217324\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVR(kernel=\"linear\")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('SVM (linear) Regressor Accuracy:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (rbf) Regressor Accuracy: 0.11993845783691613\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVR(kernel=\"rbf\")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('SVM (rbf) Regressor Accuracy:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state=0,n_estimators=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Accuracy: 0.5202389704056603\n"
     ]
    }
   ],
   "source": [
    "print ('Random Forest Regressor Accuracy:', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "X = pd.read_excel('test.xlsx')\n",
    "X=X.drop(X.columns[0:2],axis=1)\n",
    "y = pd.DataFrame(X['domain1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>58.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               essay  domain1_score\n",
       "0  Dear local newspaper, I think effects computer...      66.666667\n",
       "1  Dear @CAPS1 @CAPS2, I believe that using compu...      75.000000\n",
       "2  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...      58.333333\n",
       "3  Dear Local Newspaper, @CAPS1 I have found that...      83.333333\n",
       "4  Dear @LOCATION1, I know having computers has a...      66.666667"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   domain1_score\n",
       "0      66.666667\n",
       "1      75.000000\n",
       "2      58.333333\n",
       "3      83.333333\n",
       "4      66.666667"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential, load_model, model_from_config\n",
    "import keras.backend as K\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential([\n",
    "        # 2D tensor for first layer: 1 timestep and 300 features\n",
    "        LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True),\n",
    "        LSTM(64, recurrent_dropout=0.4),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='relu')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def essay_to_list(essay):\n",
    "    # Remove the tags\n",
    "    essay = re.sub(\"[^a-zA-Z]\", \" \", essay)\n",
    "    words = essay.lower().split()\n",
    "    return [w for w in words if not w in stopwords]\n",
    "\n",
    "def essay_to_sentences(essay):\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(essay.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(essay_to_list(raw_sentence))\n",
    "    return sentences\n",
    "\n",
    "# Generate feature vector for the words\n",
    "def get_feature_vector(words, model, num_features, vec_type=\"sum\"):\n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float32\")\n",
    "    num_words = 0.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    max_vec =  np.zeros((num_features,),dtype=\"float32\")\n",
    "    min_vec =  np.ones((num_features,),dtype=\"float32\")\n",
    "\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            num_words += 1\n",
    "            max_vec = np.maximum(model[word], feature_vector)\n",
    "            min_vec = np.minimum(model[word], feature_vector)\n",
    "            feature_vector = np.add(feature_vector, model[word]) \n",
    "    \n",
    "    # return min vector + max vector\n",
    "    if vec_type == \"min+max\":\n",
    "        return np.add(min_vec, max_vec) \n",
    "    \n",
    "    # average of vectors\n",
    "    elif vec_type == \"average\":\n",
    "        return np.divide(feature_vector, num_words)\n",
    "\n",
    "    # default: return sum of word2vec vectors\n",
    "    return feature_vector\n",
    "\n",
    "# Generate word vectors from the mdoel\n",
    "def generate_essay_vectors(essays, model, num_features, vec_type=\"sum\"):\n",
    "    essayfeature_vectors = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for (i, essay) in enumerate(essays):\n",
    "        essayfeature_vectors[i] = get_feature_vector(essay, model, num_features, vec_type)\n",
    "    return essayfeature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def train_model(X, y, dataset, vec_type=\"sum\"):\n",
    "    count = 1\n",
    "    results = []\n",
    "    \n",
    "    for train_set, test_set in dataset:\n",
    "        print(\"Fold #\", count)\n",
    "        X_test, X_train, y_test, y_train = X.iloc[test_set], X.iloc[train_set], y.iloc[test_set], y.iloc[train_set]\n",
    "        \n",
    "        train_essays = X_train['essay']\n",
    "        test_essays = X_test['essay']\n",
    "        \n",
    "        sentences = []\n",
    "        \n",
    "        for essay in train_essays:\n",
    "            sentences += essay_to_sentences(essay)\n",
    "                \n",
    "        # Initialize variables for word2vec model\n",
    "        num_features = 300 \n",
    "        min_word_count = 40\n",
    "        num_workers = 4\n",
    "        context = 10\n",
    "        downsampling = 1e-7\n",
    "\n",
    "        # Train the word2vec model\n",
    "        model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "        model.init_sims(replace=True)\n",
    "        \n",
    "        # Generate training vectors\n",
    "        clean_train_essays = []\n",
    "        for essay_vec in train_essays:\n",
    "            clean_train_essays.append(essay_to_list(essay_vec))\n",
    "        train_vectors = generate_essay_vectors(clean_train_essays, model, num_features, vec_type)\n",
    "        \n",
    "        # Generate test vectors\n",
    "        clean_test_essays = []\n",
    "        for essay_vec in test_essays:\n",
    "            clean_test_essays.append(essay_to_list( essay_vec))\n",
    "        test_vectors = generate_essay_vectors(clean_test_essays, model, num_features, vec_type)\n",
    "        \n",
    "        train_vectors = np.array(train_vectors)\n",
    "        test_vectors = np.array(test_vectors)\n",
    "\n",
    "        # Reshape the train and test vectors to 3 dimensions - 1 represents one timestamp \n",
    "        train_vectors = np.reshape(train_vectors, (train_vectors.shape[0], 1, train_vectors.shape[1]))\n",
    "        test_vectors = np.reshape(test_vectors, (test_vectors.shape[0], 1, test_vectors.shape[1]))\n",
    "        \n",
    "        # Call the LSTM to get the score predictions \n",
    "        lstm_model = get_model()\n",
    "        lstm_model.fit(train_vectors, y_train, batch_size=64, epochs=50)\n",
    "        y_pred = lstm_model.predict(test_vectors)\n",
    "        \n",
    "        # Round the prediction to the nearest integer\n",
    "        y_pred = np.around(y_pred)\n",
    "        \n",
    "        # Evaluate the model: quadratic kappa score of predictions against human grading\n",
    "        result = cohen_kappa_score(y_test.values, y_pred, weights='quadratic')\n",
    "        print(\"QWK: \", result)\n",
    "        results.append(result)\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold # 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:36: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:37: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:38: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "10366/10366 [==============================] - 9s 889us/step - loss: 3157.1185 - mean_absolute_error: 51.8559\n",
      "Epoch 2/50\n",
      "10366/10366 [==============================] - 7s 671us/step - loss: 2350.6871 - mean_absolute_error: 43.7440\n",
      "Epoch 3/50\n",
      "10366/10366 [==============================] - 6s 587us/step - loss: 1753.2471 - mean_absolute_error: 36.7699\n",
      "Epoch 4/50\n",
      "10366/10366 [==============================] - 6s 597us/step - loss: 1269.5349 - mean_absolute_error: 30.7102\n",
      "Epoch 5/50\n",
      "10366/10366 [==============================] - 6s 584us/step - loss: 911.4441 - mean_absolute_error: 25.4534\n",
      "Epoch 6/50\n",
      "10366/10366 [==============================] - 8s 796us/step - loss: 641.1626 - mean_absolute_error: 20.8214\n",
      "Epoch 7/50\n",
      "10366/10366 [==============================] - 6s 614us/step - loss: 480.3761 - mean_absolute_error: 17.4833\n",
      "Epoch 8/50\n",
      "10366/10366 [==============================] - 6s 593us/step - loss: 378.3653 - mean_absolute_error: 15.3215\n",
      "Epoch 9/50\n",
      "10366/10366 [==============================] - 6s 570us/step - loss: 340.4755 - mean_absolute_error: 14.4680\n",
      "Epoch 10/50\n",
      "10366/10366 [==============================] - 8s 802us/step - loss: 314.1818 - mean_absolute_error: 13.9185\n",
      "Epoch 11/50\n",
      "10366/10366 [==============================] - 7s 711us/step - loss: 301.1075 - mean_absolute_error: 13.6044\n",
      "Epoch 12/50\n",
      "10366/10366 [==============================] - 8s 738us/step - loss: 286.8692 - mean_absolute_error: 13.3041\n",
      "Epoch 13/50\n",
      "10366/10366 [==============================] - 7s 706us/step - loss: 275.5966 - mean_absolute_error: 13.0464\n",
      "Epoch 14/50\n",
      "10366/10366 [==============================] - 7s 692us/step - loss: 269.3655 - mean_absolute_error: 12.9130\n",
      "Epoch 15/50\n",
      "10366/10366 [==============================] - 8s 735us/step - loss: 265.4169 - mean_absolute_error: 12.7989\n",
      "Epoch 16/50\n",
      "10366/10366 [==============================] - 8s 799us/step - loss: 257.2173 - mean_absolute_error: 12.5837\n",
      "Epoch 17/50\n",
      "10366/10366 [==============================] - 8s 779us/step - loss: 246.6894 - mean_absolute_error: 12.2667\n",
      "Epoch 18/50\n",
      "10366/10366 [==============================] - 11s 1ms/step - loss: 247.6098 - mean_absolute_error: 12.2947\n",
      "Epoch 19/50\n",
      "10366/10366 [==============================] - 8s 815us/step - loss: 243.5906 - mean_absolute_error: 12.1718\n",
      "Epoch 20/50\n",
      "10366/10366 [==============================] - 8s 798us/step - loss: 242.7072 - mean_absolute_error: 12.1650\n",
      "Epoch 21/50\n",
      "10366/10366 [==============================] - 10s 990us/step - loss: 234.1796 - mean_absolute_error: 11.9761\n",
      "Epoch 22/50\n",
      "10366/10366 [==============================] - 9s 868us/step - loss: 229.5015 - mean_absolute_error: 11.8158\n",
      "Epoch 23/50\n",
      "10366/10366 [==============================] - 8s 808us/step - loss: 226.0308 - mean_absolute_error: 11.7622\n",
      "Epoch 24/50\n",
      "10366/10366 [==============================] - 8s 804us/step - loss: 219.8537 - mean_absolute_error: 11.5423\n",
      "Epoch 25/50\n",
      "10366/10366 [==============================] - 9s 856us/step - loss: 216.7027 - mean_absolute_error: 11.4458\n",
      "Epoch 26/50\n",
      "10366/10366 [==============================] - 6s 614us/step - loss: 215.7303 - mean_absolute_error: 11.5248\n",
      "Epoch 27/50\n",
      "10366/10366 [==============================] - 8s 813us/step - loss: 214.4016 - mean_absolute_error: 11.3813\n",
      "Epoch 28/50\n",
      "10366/10366 [==============================] - 9s 875us/step - loss: 210.6433 - mean_absolute_error: 11.3348\n",
      "Epoch 29/50\n",
      "10366/10366 [==============================] - 8s 731us/step - loss: 206.0975 - mean_absolute_error: 11.2301\n",
      "Epoch 30/50\n",
      "10366/10366 [==============================] - 8s 748us/step - loss: 200.6704 - mean_absolute_error: 11.0242\n",
      "Epoch 31/50\n",
      "10366/10366 [==============================] - 8s 736us/step - loss: 197.4577 - mean_absolute_error: 11.0060\n",
      "Epoch 32/50\n",
      "10366/10366 [==============================] - 10s 994us/step - loss: 195.2993 - mean_absolute_error: 10.8861\n",
      "Epoch 33/50\n",
      "10366/10366 [==============================] - 9s 897us/step - loss: 190.5595 - mean_absolute_error: 10.7911\n",
      "Epoch 34/50\n",
      "10366/10366 [==============================] - 8s 744us/step - loss: 183.0155 - mean_absolute_error: 10.5408\n",
      "Epoch 35/50\n",
      "10366/10366 [==============================] - 8s 760us/step - loss: 183.8650 - mean_absolute_error: 10.5847\n",
      "Epoch 36/50\n",
      "10366/10366 [==============================] - 10s 1000us/step - loss: 181.2436 - mean_absolute_error: 10.4950\n",
      "Epoch 37/50\n",
      "10366/10366 [==============================] - 8s 752us/step - loss: 182.8775 - mean_absolute_error: 10.5419\n",
      "Epoch 38/50\n",
      "10366/10366 [==============================] - 8s 758us/step - loss: 175.5477 - mean_absolute_error: 10.2436\n",
      "Epoch 39/50\n",
      "10366/10366 [==============================] - 8s 751us/step - loss: 175.9753 - mean_absolute_error: 10.3013\n",
      "Epoch 40/50\n",
      "10366/10366 [==============================] - 8s 764us/step - loss: 173.9232 - mean_absolute_error: 10.2751\n",
      "Epoch 41/50\n",
      "10366/10366 [==============================] - 8s 744us/step - loss: 168.1636 - mean_absolute_error: 10.1243\n",
      "Epoch 42/50\n",
      "10366/10366 [==============================] - 8s 750us/step - loss: 166.8438 - mean_absolute_error: 10.0367\n",
      "Epoch 43/50\n",
      "10366/10366 [==============================] - 8s 779us/step - loss: 168.2211 - mean_absolute_error: 10.0962\n",
      "Epoch 44/50\n",
      "10366/10366 [==============================] - 8s 760us/step - loss: 167.0291 - mean_absolute_error: 10.0394\n",
      "Epoch 45/50\n",
      "10366/10366 [==============================] - 8s 761us/step - loss: 163.4358 - mean_absolute_error: 9.9480\n",
      "Epoch 46/50\n",
      "10366/10366 [==============================] - 10s 975us/step - loss: 159.7103 - mean_absolute_error: 9.9005\n",
      "Epoch 47/50\n",
      "10366/10366 [==============================] - 9s 840us/step - loss: 161.0010 - mean_absolute_error: 9.8533\n",
      "Epoch 48/50\n",
      "10366/10366 [==============================] - 8s 730us/step - loss: 160.6200 - mean_absolute_error: 9.8540\n",
      "Epoch 49/50\n",
      "10366/10366 [==============================] - 8s 795us/step - loss: 156.5669 - mean_absolute_error: 9.7304\n",
      "Epoch 50/50\n",
      "10366/10366 [==============================] - 10s 951us/step - loss: 154.9844 - mean_absolute_error: 9.7199\n",
      "QWK:  0.7552342138810835\n",
      "Fold # 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10371/10371 [==============================] - 8s 760us/step - loss: 3203.5020 - mean_absolute_error: 52.2249\n",
      "Epoch 2/50\n",
      "10371/10371 [==============================] - 6s 536us/step - loss: 2380.7418 - mean_absolute_error: 44.1044\n",
      "Epoch 3/50\n",
      "10371/10371 [==============================] - 8s 727us/step - loss: 1774.9959 - mean_absolute_error: 37.0654\n",
      "Epoch 4/50\n",
      "10371/10371 [==============================] - 7s 650us/step - loss: 1293.9616 - mean_absolute_error: 31.0081\n",
      "Epoch 5/50\n",
      "10371/10371 [==============================] - 6s 544us/step - loss: 917.1753 - mean_absolute_error: 25.5850\n",
      "Epoch 6/50\n",
      "10371/10371 [==============================] - 8s 736us/step - loss: 653.3926 - mean_absolute_error: 21.0454\n",
      "Epoch 7/50\n",
      "10371/10371 [==============================] - 7s 647us/step - loss: 480.9029 - mean_absolute_error: 17.5797\n",
      "Epoch 8/50\n",
      "10371/10371 [==============================] - 7s 661us/step - loss: 385.3684 - mean_absolute_error: 15.4687\n",
      "Epoch 9/50\n",
      "10371/10371 [==============================] - 7s 642us/step - loss: 333.1146 - mean_absolute_error: 14.4149\n",
      "Epoch 10/50\n",
      "10371/10371 [==============================] - 7s 635us/step - loss: 315.4427 - mean_absolute_error: 14.0004\n",
      "Epoch 11/50\n",
      "10371/10371 [==============================] - 6s 620us/step - loss: 302.3537 - mean_absolute_error: 13.7429\n",
      "Epoch 12/50\n",
      "10371/10371 [==============================] - 7s 627us/step - loss: 287.3835 - mean_absolute_error: 13.3071\n",
      "Epoch 13/50\n",
      "10371/10371 [==============================] - 7s 635us/step - loss: 278.6910 - mean_absolute_error: 13.1002\n",
      "Epoch 14/50\n",
      "10371/10371 [==============================] - 7s 649us/step - loss: 272.6289 - mean_absolute_error: 12.9623\n",
      "Epoch 15/50\n",
      "10371/10371 [==============================] - 7s 649us/step - loss: 260.4130 - mean_absolute_error: 12.6654\n",
      "Epoch 16/50\n",
      "10371/10371 [==============================] - 7s 644us/step - loss: 258.6647 - mean_absolute_error: 12.5924\n",
      "Epoch 17/50\n",
      "10371/10371 [==============================] - 7s 636us/step - loss: 251.9288 - mean_absolute_error: 12.4459\n",
      "Epoch 18/50\n",
      "10371/10371 [==============================] - 7s 642us/step - loss: 248.7897 - mean_absolute_error: 12.3422\n",
      "Epoch 19/50\n",
      "10371/10371 [==============================] - 9s 873us/step - loss: 240.8738 - mean_absolute_error: 12.1360\n",
      "Epoch 20/50\n",
      "10371/10371 [==============================] - 7s 716us/step - loss: 243.5960 - mean_absolute_error: 12.1970\n",
      "Epoch 21/50\n",
      "10371/10371 [==============================] - 7s 672us/step - loss: 235.9605 - mean_absolute_error: 12.0553\n",
      "Epoch 22/50\n",
      "10371/10371 [==============================] - 6s 572us/step - loss: 233.4962 - mean_absolute_error: 11.9639\n",
      "Epoch 23/50\n",
      "10371/10371 [==============================] - 6s 576us/step - loss: 223.8396 - mean_absolute_error: 11.7018\n",
      "Epoch 24/50\n",
      "10371/10371 [==============================] - 8s 768us/step - loss: 226.5025 - mean_absolute_error: 11.8243\n",
      "Epoch 25/50\n",
      "10371/10371 [==============================] - 7s 652us/step - loss: 220.6090 - mean_absolute_error: 11.5927\n",
      "Epoch 26/50\n",
      "10371/10371 [==============================] - 7s 640us/step - loss: 217.8023 - mean_absolute_error: 11.5473\n",
      "Epoch 27/50\n",
      "10371/10371 [==============================] - 7s 645us/step - loss: 214.9041 - mean_absolute_error: 11.4632\n",
      "Epoch 28/50\n",
      "10371/10371 [==============================] - 7s 661us/step - loss: 211.3488 - mean_absolute_error: 11.3550\n",
      "Epoch 29/50\n",
      "10371/10371 [==============================] - 6s 544us/step - loss: 204.9695 - mean_absolute_error: 11.1440\n",
      "Epoch 30/50\n",
      "10371/10371 [==============================] - 8s 724us/step - loss: 201.0026 - mean_absolute_error: 11.0828\n",
      "Epoch 31/50\n",
      "10371/10371 [==============================] - 10s 939us/step - loss: 196.0796 - mean_absolute_error: 10.8850\n",
      "Epoch 32/50\n",
      "10371/10371 [==============================] - 10s 953us/step - loss: 194.1930 - mean_absolute_error: 10.9557\n",
      "Epoch 33/50\n",
      "10371/10371 [==============================] - 7s 635us/step - loss: 191.8154 - mean_absolute_error: 10.8050\n",
      "Epoch 34/50\n",
      "10371/10371 [==============================] - 5s 527us/step - loss: 185.2716 - mean_absolute_error: 10.6603\n",
      "Epoch 35/50\n",
      "10371/10371 [==============================] - 7s 643us/step - loss: 187.2851 - mean_absolute_error: 10.6951\n",
      "Epoch 36/50\n",
      "10371/10371 [==============================] - 7s 672us/step - loss: 188.7700 - mean_absolute_error: 10.7043\n",
      "Epoch 37/50\n",
      "10371/10371 [==============================] - 7s 634us/step - loss: 183.5103 - mean_absolute_error: 10.5476\n",
      "Epoch 38/50\n",
      "10371/10371 [==============================] - 6s 613us/step - loss: 180.9555 - mean_absolute_error: 10.5018\n",
      "Epoch 39/50\n",
      "10371/10371 [==============================] - 6s 619us/step - loss: 179.3448 - mean_absolute_error: 10.4194\n",
      "Epoch 40/50\n",
      "10371/10371 [==============================] - 6s 625us/step - loss: 176.0347 - mean_absolute_error: 10.3203\n",
      "Epoch 41/50\n",
      "10371/10371 [==============================] - 7s 634us/step - loss: 172.1332 - mean_absolute_error: 10.2435\n",
      "Epoch 42/50\n",
      "10371/10371 [==============================] - 7s 629us/step - loss: 165.8907 - mean_absolute_error: 10.0541\n",
      "Epoch 43/50\n",
      "10371/10371 [==============================] - 7s 630us/step - loss: 168.1015 - mean_absolute_error: 10.1202\n",
      "Epoch 44/50\n",
      "10371/10371 [==============================] - 6s 619us/step - loss: 167.7604 - mean_absolute_error: 10.0940\n",
      "Epoch 45/50\n",
      "10371/10371 [==============================] - 6s 625us/step - loss: 162.9848 - mean_absolute_error: 9.9753\n",
      "Epoch 46/50\n",
      "10371/10371 [==============================] - 7s 635us/step - loss: 163.1198 - mean_absolute_error: 9.9820\n",
      "Epoch 47/50\n",
      "10371/10371 [==============================] - 7s 637us/step - loss: 160.7596 - mean_absolute_error: 9.8777\n",
      "Epoch 48/50\n",
      "10371/10371 [==============================] - 7s 630us/step - loss: 160.9004 - mean_absolute_error: 9.9200\n",
      "Epoch 49/50\n",
      "10371/10371 [==============================] - 6s 621us/step - loss: 160.6182 - mean_absolute_error: 9.8659\n",
      "Epoch 50/50\n",
      "10371/10371 [==============================] - 6s 621us/step - loss: 162.8414 - mean_absolute_error: 9.9128\n",
      "QWK:  0.7723076156805782\n",
      "Fold # 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10382/10382 [==============================] - 7s 699us/step - loss: 3135.3205 - mean_absolute_error: 51.5734\n",
      "Epoch 2/50\n",
      "10382/10382 [==============================] - 6s 620us/step - loss: 2325.7077 - mean_absolute_error: 43.4828\n",
      "Epoch 3/50\n",
      "10382/10382 [==============================] - 7s 651us/step - loss: 1730.5004 - mean_absolute_error: 36.4785\n",
      "Epoch 4/50\n",
      "10382/10382 [==============================] - 9s 886us/step - loss: 1252.0141 - mean_absolute_error: 30.4019\n",
      "Epoch 5/50\n",
      "10382/10382 [==============================] - 7s 639us/step - loss: 891.0005 - mean_absolute_error: 25.1116\n",
      "Epoch 6/50\n",
      "10382/10382 [==============================] - 7s 644us/step - loss: 635.3317 - mean_absolute_error: 20.6425\n",
      "Epoch 7/50\n",
      "10382/10382 [==============================] - 7s 648us/step - loss: 464.6724 - mean_absolute_error: 17.1760\n",
      "Epoch 8/50\n",
      "10382/10382 [==============================] - 7s 640us/step - loss: 377.1602 - mean_absolute_error: 15.2355\n",
      "Epoch 9/50\n",
      "10382/10382 [==============================] - 7s 636us/step - loss: 332.8967 - mean_absolute_error: 14.3837\n",
      "Epoch 10/50\n",
      "10382/10382 [==============================] - 7s 636us/step - loss: 308.6294 - mean_absolute_error: 13.8043\n",
      "Epoch 11/50\n",
      "10382/10382 [==============================] - 6s 598us/step - loss: 294.7439 - mean_absolute_error: 13.5389\n",
      "Epoch 12/50\n",
      "10382/10382 [==============================] - 5s 506us/step - loss: 287.8827 - mean_absolute_error: 13.3175\n",
      "Epoch 13/50\n",
      "10382/10382 [==============================] - 6s 609us/step - loss: 276.2202 - mean_absolute_error: 13.1186\n",
      "Epoch 14/50\n",
      "10382/10382 [==============================] - 7s 640us/step - loss: 266.4624 - mean_absolute_error: 12.8389\n",
      "Epoch 15/50\n",
      "10382/10382 [==============================] - 6s 600us/step - loss: 258.8809 - mean_absolute_error: 12.6404\n",
      "Epoch 16/50\n",
      "10382/10382 [==============================] - 6s 589us/step - loss: 255.9314 - mean_absolute_error: 12.5914\n",
      "Epoch 17/50\n",
      "10382/10382 [==============================] - 6s 602us/step - loss: 246.8126 - mean_absolute_error: 12.3107\n",
      "Epoch 18/50\n",
      "10382/10382 [==============================] - 7s 627us/step - loss: 246.9305 - mean_absolute_error: 12.3627\n",
      "Epoch 19/50\n",
      "10382/10382 [==============================] - 6s 611us/step - loss: 241.3207 - mean_absolute_error: 12.2139\n",
      "Epoch 20/50\n",
      "10382/10382 [==============================] - 6s 612us/step - loss: 240.4367 - mean_absolute_error: 12.1160\n",
      "Epoch 21/50\n",
      "10382/10382 [==============================] - 6s 600us/step - loss: 234.0275 - mean_absolute_error: 11.9818\n",
      "Epoch 22/50\n",
      "10382/10382 [==============================] - 6s 600us/step - loss: 227.5090 - mean_absolute_error: 11.7712\n",
      "Epoch 23/50\n",
      "10382/10382 [==============================] - 8s 723us/step - loss: 226.1316 - mean_absolute_error: 11.7702\n",
      "Epoch 24/50\n",
      "10382/10382 [==============================] - 8s 752us/step - loss: 222.5786 - mean_absolute_error: 11.7115\n",
      "Epoch 25/50\n",
      "10382/10382 [==============================] - 6s 583us/step - loss: 216.0289 - mean_absolute_error: 11.4987\n",
      "Epoch 26/50\n",
      "10382/10382 [==============================] - 5s 517us/step - loss: 213.7885 - mean_absolute_error: 11.4317\n",
      "Epoch 27/50\n",
      "10382/10382 [==============================] - 7s 699us/step - loss: 214.5232 - mean_absolute_error: 11.4458\n",
      "Epoch 28/50\n",
      "10382/10382 [==============================] - 6s 610us/step - loss: 208.9107 - mean_absolute_error: 11.2922\n",
      "Epoch 29/50\n",
      "10382/10382 [==============================] - 6s 617us/step - loss: 206.2211 - mean_absolute_error: 11.2800\n",
      "Epoch 30/50\n",
      "10382/10382 [==============================] - 7s 627us/step - loss: 195.6932 - mean_absolute_error: 10.9290\n",
      "Epoch 31/50\n",
      "10382/10382 [==============================] - 6s 545us/step - loss: 194.4801 - mean_absolute_error: 10.9145\n",
      "Epoch 32/50\n",
      "10382/10382 [==============================] - 6s 547us/step - loss: 190.0525 - mean_absolute_error: 10.7536\n",
      "Epoch 33/50\n",
      "10382/10382 [==============================] - 8s 728us/step - loss: 191.3119 - mean_absolute_error: 10.8360\n",
      "Epoch 34/50\n",
      "10382/10382 [==============================] - 6s 607us/step - loss: 187.7345 - mean_absolute_error: 10.6819\n",
      "Epoch 35/50\n",
      "10382/10382 [==============================] - 6s 609us/step - loss: 187.2219 - mean_absolute_error: 10.6700\n",
      "Epoch 36/50\n",
      "10382/10382 [==============================] - 7s 627us/step - loss: 182.3502 - mean_absolute_error: 10.5518\n",
      "Epoch 37/50\n",
      "10382/10382 [==============================] - 7s 627us/step - loss: 178.8049 - mean_absolute_error: 10.3853\n",
      "Epoch 38/50\n",
      "10382/10382 [==============================] - 6s 545us/step - loss: 175.6391 - mean_absolute_error: 10.3278\n",
      "Epoch 39/50\n",
      "10382/10382 [==============================] - 6s 571us/step - loss: 174.8389 - mean_absolute_error: 10.2923\n",
      "Epoch 40/50\n",
      "10382/10382 [==============================] - 8s 723us/step - loss: 174.7815 - mean_absolute_error: 10.3284\n",
      "Epoch 41/50\n",
      "10382/10382 [==============================] - 6s 558us/step - loss: 169.1887 - mean_absolute_error: 10.1390\n",
      "Epoch 42/50\n",
      "10382/10382 [==============================] - 6s 548us/step - loss: 170.3111 - mean_absolute_error: 10.2078\n",
      "Epoch 43/50\n",
      "10382/10382 [==============================] - 8s 723us/step - loss: 168.6280 - mean_absolute_error: 10.1628\n",
      "Epoch 44/50\n",
      "10382/10382 [==============================] - 6s 613us/step - loss: 167.1819 - mean_absolute_error: 10.0334\n",
      "Epoch 45/50\n",
      "10382/10382 [==============================] - 6s 616us/step - loss: 161.0006 - mean_absolute_error: 9.8873\n",
      "Epoch 46/50\n",
      "10382/10382 [==============================] - 7s 634us/step - loss: 164.8228 - mean_absolute_error: 10.0336\n",
      "Epoch 47/50\n",
      "10382/10382 [==============================] - 7s 635us/step - loss: 163.4962 - mean_absolute_error: 9.9577\n",
      "Epoch 48/50\n",
      "10382/10382 [==============================] - 6s 546us/step - loss: 158.9695 - mean_absolute_error: 9.8596\n",
      "Epoch 49/50\n",
      "10382/10382 [==============================] - 6s 574us/step - loss: 159.0975 - mean_absolute_error: 9.7995\n",
      "Epoch 50/50\n",
      "10382/10382 [==============================] - 7s 721us/step - loss: 150.0334 - mean_absolute_error: 9.5426\n",
      "QWK:  0.7612445296310297\n",
      "Fold # 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10390/10390 [==============================] - 9s 827us/step - loss: 3206.3663 - mean_absolute_error: 52.2843\n",
      "Epoch 2/50\n",
      "10390/10390 [==============================] - 6s 545us/step - loss: 2393.6197 - mean_absolute_error: 44.2134\n",
      "Epoch 3/50\n",
      "10390/10390 [==============================] - 6s 602us/step - loss: 1782.3390 - mean_absolute_error: 37.1395\n",
      "Epoch 4/50\n",
      "10390/10390 [==============================] - 7s 719us/step - loss: 1296.8949 - mean_absolute_error: 31.0195\n",
      "Epoch 5/50\n",
      "10390/10390 [==============================] - 6s 554us/step - loss: 923.8565 - mean_absolute_error: 25.6983\n",
      "Epoch 6/50\n",
      "10390/10390 [==============================] - 6s 572us/step - loss: 657.4133 - mean_absolute_error: 21.0491\n",
      "Epoch 7/50\n",
      "10390/10390 [==============================] - 8s 730us/step - loss: 484.6219 - mean_absolute_error: 17.5433\n",
      "Epoch 8/50\n",
      "10390/10390 [==============================] - 7s 631us/step - loss: 387.3529 - mean_absolute_error: 15.5229\n",
      "Epoch 9/50\n",
      "10390/10390 [==============================] - 7s 629us/step - loss: 335.1569 - mean_absolute_error: 14.4102\n",
      "Epoch 10/50\n",
      "10390/10390 [==============================] - 7s 640us/step - loss: 317.4327 - mean_absolute_error: 14.0808\n",
      "Epoch 11/50\n",
      "10390/10390 [==============================] - 7s 644us/step - loss: 300.5578 - mean_absolute_error: 13.6767\n",
      "Epoch 12/50\n",
      "10390/10390 [==============================] - 7s 636us/step - loss: 286.1697 - mean_absolute_error: 13.3412\n",
      "Epoch 13/50\n",
      "10390/10390 [==============================] - 7s 627us/step - loss: 277.0366 - mean_absolute_error: 13.1309\n",
      "Epoch 14/50\n",
      "10390/10390 [==============================] - 6s 625us/step - loss: 268.0710 - mean_absolute_error: 12.9117\n",
      "Epoch 15/50\n",
      "10390/10390 [==============================] - 7s 638us/step - loss: 258.5246 - mean_absolute_error: 12.6629\n",
      "Epoch 16/50\n",
      "10390/10390 [==============================] - 7s 647us/step - loss: 253.1593 - mean_absolute_error: 12.5105\n",
      "Epoch 17/50\n",
      "10390/10390 [==============================] - 6s 544us/step - loss: 252.4110 - mean_absolute_error: 12.4859\n",
      "Epoch 18/50\n",
      "10390/10390 [==============================] - 7s 632us/step - loss: 241.7073 - mean_absolute_error: 12.1944\n",
      "Epoch 19/50\n",
      "10390/10390 [==============================] - 7s 709us/step - loss: 237.7281 - mean_absolute_error: 12.0489\n",
      "Epoch 20/50\n",
      "10390/10390 [==============================] - 7s 646us/step - loss: 238.5677 - mean_absolute_error: 12.0906\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10390/10390 [==============================] - 6s 586us/step - loss: 230.7530 - mean_absolute_error: 11.8589\n",
      "Epoch 22/50\n",
      "10390/10390 [==============================] - 6s 583us/step - loss: 229.6627 - mean_absolute_error: 11.8673\n",
      "Epoch 23/50\n",
      "10390/10390 [==============================] - 5s 500us/step - loss: 224.5145 - mean_absolute_error: 11.7568\n",
      "Epoch 24/50\n",
      "10390/10390 [==============================] - 7s 635us/step - loss: 224.2252 - mean_absolute_error: 11.6981\n",
      "Epoch 25/50\n",
      "10390/10390 [==============================] - 7s 657us/step - loss: 222.5525 - mean_absolute_error: 11.6024\n",
      "Epoch 26/50\n",
      "10390/10390 [==============================] - 7s 639us/step - loss: 212.9379 - mean_absolute_error: 11.4209\n",
      "Epoch 27/50\n",
      "10390/10390 [==============================] - 6s 604us/step - loss: 210.6817 - mean_absolute_error: 11.2648\n",
      "Epoch 28/50\n",
      "10390/10390 [==============================] - 6s 552us/step - loss: 201.6098 - mean_absolute_error: 11.0916\n",
      "Epoch 29/50\n",
      "10390/10390 [==============================] - 5s 523us/step - loss: 199.6743 - mean_absolute_error: 11.0338\n",
      "Epoch 30/50\n",
      "10390/10390 [==============================] - 7s 663us/step - loss: 203.2177 - mean_absolute_error: 11.0852\n",
      "Epoch 31/50\n",
      "10390/10390 [==============================] - 6s 594us/step - loss: 197.4669 - mean_absolute_error: 10.9396\n",
      "Epoch 32/50\n",
      "10390/10390 [==============================] - 6s 618us/step - loss: 195.2101 - mean_absolute_error: 10.8741\n",
      "Epoch 33/50\n",
      "10390/10390 [==============================] - 5s 516us/step - loss: 192.7663 - mean_absolute_error: 10.8366\n",
      "Epoch 34/50\n",
      "10390/10390 [==============================] - 6s 605us/step - loss: 189.1681 - mean_absolute_error: 10.7111\n",
      "Epoch 35/50\n",
      "10390/10390 [==============================] - 7s 671us/step - loss: 177.7523 - mean_absolute_error: 10.4152\n",
      "Epoch 36/50\n",
      "10390/10390 [==============================] - 6s 611us/step - loss: 182.2660 - mean_absolute_error: 10.5093\n",
      "Epoch 37/50\n",
      "10390/10390 [==============================] - 6s 596us/step - loss: 179.2322 - mean_absolute_error: 10.3718\n",
      "Epoch 38/50\n",
      "10390/10390 [==============================] - 6s 601us/step - loss: 182.1388 - mean_absolute_error: 10.5032\n",
      "Epoch 39/50\n",
      "10390/10390 [==============================] - 6s 615us/step - loss: 174.3943 - mean_absolute_error: 10.2971\n",
      "Epoch 40/50\n",
      "10390/10390 [==============================] - 5s 521us/step - loss: 177.3290 - mean_absolute_error: 10.3631\n",
      "Epoch 41/50\n",
      "10390/10390 [==============================] - 6s 599us/step - loss: 170.9145 - mean_absolute_error: 10.1431\n",
      "Epoch 42/50\n",
      "10390/10390 [==============================] - 7s 680us/step - loss: 170.0154 - mean_absolute_error: 10.1332\n",
      "Epoch 43/50\n",
      "10390/10390 [==============================] - 6s 608us/step - loss: 167.1331 - mean_absolute_error: 10.0695\n",
      "Epoch 44/50\n",
      "10390/10390 [==============================] - 6s 603us/step - loss: 170.2903 - mean_absolute_error: 10.1524\n",
      "Epoch 45/50\n",
      "10390/10390 [==============================] - 6s 608us/step - loss: 161.5027 - mean_absolute_error: 9.8833\n",
      "Epoch 46/50\n",
      "10390/10390 [==============================] - 6s 624us/step - loss: 162.6885 - mean_absolute_error: 9.9456\n",
      "Epoch 47/50\n",
      "10390/10390 [==============================] - 7s 627us/step - loss: 158.3218 - mean_absolute_error: 9.8091\n",
      "Epoch 48/50\n",
      "10390/10390 [==============================] - 6s 546us/step - loss: 160.8366 - mean_absolute_error: 9.8540\n",
      "Epoch 49/50\n",
      "10390/10390 [==============================] - 6s 551us/step - loss: 156.8728 - mean_absolute_error: 9.7783\n",
      "Epoch 50/50\n",
      "10390/10390 [==============================] - 8s 723us/step - loss: 154.7467 - mean_absolute_error: 9.6967\n",
      "QWK:  0.7606862851658096\n",
      "Fold # 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10403/10403 [==============================] - 9s 883us/step - loss: 3157.5892 - mean_absolute_error: 51.8460\n",
      "Epoch 2/50\n",
      "10403/10403 [==============================] - 7s 633us/step - loss: 2344.0443 - mean_absolute_error: 43.6787\n",
      "Epoch 3/50\n",
      "10403/10403 [==============================] - 6s 566us/step - loss: 1742.4283 - mean_absolute_error: 36.6655\n",
      "Epoch 4/50\n",
      "10403/10403 [==============================] - 6s 554us/step - loss: 1266.9517 - mean_absolute_error: 30.6444\n",
      "Epoch 5/50\n",
      "10403/10403 [==============================] - 8s 731us/step - loss: 898.7649 - mean_absolute_error: 25.2112\n",
      "Epoch 6/50\n",
      "10403/10403 [==============================] - 6s 623us/step - loss: 641.6564 - mean_absolute_error: 20.7700\n",
      "Epoch 7/50\n",
      "10403/10403 [==============================] - 6s 619us/step - loss: 467.9801 - mean_absolute_error: 17.2985\n",
      "Epoch 8/50\n",
      "10403/10403 [==============================] - 7s 640us/step - loss: 375.3215 - mean_absolute_error: 15.2376\n",
      "Epoch 9/50\n",
      "10403/10403 [==============================] - 7s 638us/step - loss: 336.9778 - mean_absolute_error: 14.4163\n",
      "Epoch 10/50\n",
      "10403/10403 [==============================] - 6s 544us/step - loss: 310.1253 - mean_absolute_error: 13.8666\n",
      "Epoch 11/50\n",
      "10403/10403 [==============================] - 6s 615us/step - loss: 299.2087 - mean_absolute_error: 13.6514\n",
      "Epoch 12/50\n",
      "10403/10403 [==============================] - 7s 705us/step - loss: 285.8331 - mean_absolute_error: 13.3479\n",
      "Epoch 13/50\n",
      "10403/10403 [==============================] - 7s 631us/step - loss: 278.1674 - mean_absolute_error: 13.1500\n",
      "Epoch 14/50\n",
      "10403/10403 [==============================] - 6s 621us/step - loss: 271.3536 - mean_absolute_error: 12.9996\n",
      "Epoch 15/50\n",
      "10403/10403 [==============================] - 7s 637us/step - loss: 259.3589 - mean_absolute_error: 12.6669\n",
      "Epoch 16/50\n",
      "10403/10403 [==============================] - 7s 639us/step - loss: 260.3972 - mean_absolute_error: 12.6944\n",
      "Epoch 17/50\n",
      "10403/10403 [==============================] - 7s 641us/step - loss: 254.3342 - mean_absolute_error: 12.4618\n",
      "Epoch 18/50\n",
      "10403/10403 [==============================] - 7s 646us/step - loss: 251.2039 - mean_absolute_error: 12.4349\n",
      "Epoch 19/50\n",
      "10403/10403 [==============================] - 7s 634us/step - loss: 238.9378 - mean_absolute_error: 12.1325\n",
      "Epoch 20/50\n",
      "10403/10403 [==============================] - 7s 627us/step - loss: 238.0194 - mean_absolute_error: 12.0342\n",
      "Epoch 21/50\n",
      "10403/10403 [==============================] - 7s 627us/step - loss: 232.9711 - mean_absolute_error: 11.9807\n",
      "Epoch 22/50\n",
      "10403/10403 [==============================] - 6s 531us/step - loss: 227.2819 - mean_absolute_error: 11.7917\n",
      "Epoch 23/50\n",
      "10403/10403 [==============================] - 8s 724us/step - loss: 221.5986 - mean_absolute_error: 11.71040s - loss: 222.1622 - mean\n",
      "Epoch 24/50\n",
      "10403/10403 [==============================] - 7s 636us/step - loss: 220.7544 - mean_absolute_error: 11.6251\n",
      "Epoch 25/50\n",
      "10403/10403 [==============================] - 7s 644us/step - loss: 218.0146 - mean_absolute_error: 11.5248\n",
      "Epoch 26/50\n",
      "10403/10403 [==============================] - 7s 649us/step - loss: 214.5265 - mean_absolute_error: 11.3999\n",
      "Epoch 27/50\n",
      "10403/10403 [==============================] - 7s 647us/step - loss: 213.2572 - mean_absolute_error: 11.3604\n",
      "Epoch 28/50\n",
      "10403/10403 [==============================] - 7s 629us/step - loss: 207.3294 - mean_absolute_error: 11.3018\n",
      "Epoch 29/50\n",
      "10403/10403 [==============================] - 7s 630us/step - loss: 201.4792 - mean_absolute_error: 11.0869\n",
      "Epoch 30/50\n",
      "10403/10403 [==============================] - 7s 640us/step - loss: 201.2047 - mean_absolute_error: 11.0614\n",
      "Epoch 31/50\n",
      "10403/10403 [==============================] - 6s 604us/step - loss: 200.8209 - mean_absolute_error: 11.0443\n",
      "Epoch 32/50\n",
      "10403/10403 [==============================] - 6s 599us/step - loss: 195.7482 - mean_absolute_error: 10.9124\n",
      "Epoch 33/50\n",
      "10403/10403 [==============================] - 6s 590us/step - loss: 186.6077 - mean_absolute_error: 10.6819\n",
      "Epoch 34/50\n",
      "10403/10403 [==============================] - 6s 587us/step - loss: 191.6011 - mean_absolute_error: 10.8331\n",
      "Epoch 35/50\n",
      "10403/10403 [==============================] - 6s 605us/step - loss: 182.0388 - mean_absolute_error: 10.5993\n",
      "Epoch 36/50\n",
      "10403/10403 [==============================] - 5s 505us/step - loss: 183.3465 - mean_absolute_error: 10.5957\n",
      "Epoch 37/50\n",
      "10403/10403 [==============================] - 6s 603us/step - loss: 180.7937 - mean_absolute_error: 10.5287\n",
      "Epoch 38/50\n",
      "10403/10403 [==============================] - 7s 651us/step - loss: 180.0126 - mean_absolute_error: 10.5272\n",
      "Epoch 39/50\n",
      "10403/10403 [==============================] - 6s 597us/step - loss: 173.2275 - mean_absolute_error: 10.2729\n",
      "Epoch 40/50\n",
      "10403/10403 [==============================] - 6s 591us/step - loss: 172.6007 - mean_absolute_error: 10.2755\n",
      "Epoch 41/50\n",
      "10403/10403 [==============================] - 6s 606us/step - loss: 169.2300 - mean_absolute_error: 10.1602\n",
      "Epoch 42/50\n",
      "10403/10403 [==============================] - 6s 612us/step - loss: 171.0406 - mean_absolute_error: 10.2512\n",
      "Epoch 43/50\n",
      "10403/10403 [==============================] - 6s 617us/step - loss: 163.1118 - mean_absolute_error: 9.9648\n",
      "Epoch 44/50\n",
      "10403/10403 [==============================] - 6s 596us/step - loss: 169.9649 - mean_absolute_error: 10.1795\n",
      "Epoch 45/50\n",
      "10403/10403 [==============================] - 6s 581us/step - loss: 164.3733 - mean_absolute_error: 9.9616\n",
      "Epoch 46/50\n",
      "10403/10403 [==============================] - 5s 517us/step - loss: 162.1576 - mean_absolute_error: 9.9541\n",
      "Epoch 47/50\n",
      "10403/10403 [==============================] - 7s 687us/step - loss: 161.1625 - mean_absolute_error: 9.9486\n",
      "Epoch 48/50\n",
      "10403/10403 [==============================] - 6s 615us/step - loss: 159.6843 - mean_absolute_error: 9.8178\n",
      "Epoch 49/50\n",
      "10403/10403 [==============================] - 5s 510us/step - loss: 156.5614 - mean_absolute_error: 9.7706\n",
      "Epoch 50/50\n",
      "10403/10403 [==============================] - 7s 676us/step - loss: 154.7875 - mean_absolute_error: 9.6328\n",
      "QWK:  0.7468131877146108\n",
      "Average Quadratic Weighted Kappa after 5-fold cross validation for min + max word2vec  0.7593\n"
     ]
    }
   ],
   "source": [
    "y['domain1_score']=df['domain1_score'].fillna(0.0).astype(int)\n",
    "dataset = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "dataset = dataset.split(X, y)\n",
    "results_min_max = train_model(X, y, dataset, \"min+max\")\n",
    "print(\"Average Quadratic Weighted Kappa after 5-fold cross validation for min + max word2vec \",np.around(np.array(results_min_max).mean(),decimals=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold # 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:36: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:37: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/nikshubha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:38: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10366/10366 [==============================] - 8s 782us/step - loss: 3493.2029 - mean_absolute_error: 54.5899\n",
      "Epoch 2/50\n",
      "10366/10366 [==============================] - 6s 572us/step - loss: 2360.7050 - mean_absolute_error: 43.8685\n",
      "Epoch 3/50\n",
      "10366/10366 [==============================] - 6s 569us/step - loss: 1754.8302 - mean_absolute_error: 36.8200\n",
      "Epoch 4/50\n",
      "10366/10366 [==============================] - 6s 545us/step - loss: 1286.1530 - mean_absolute_error: 30.9376\n",
      "Epoch 5/50\n",
      "10366/10366 [==============================] - 6s 600us/step - loss: 938.4939 - mean_absolute_error: 26.0626\n",
      "Epoch 6/50\n",
      "10366/10366 [==============================] - 6s 596us/step - loss: 720.5009 - mean_absolute_error: 22.2993\n",
      "Epoch 7/50\n",
      "10366/10366 [==============================] - 6s 585us/step - loss: 594.3717 - mean_absolute_error: 19.6789\n",
      "Epoch 8/50\n",
      "10366/10366 [==============================] - 6s 557us/step - loss: 534.2408 - mean_absolute_error: 18.3218\n",
      "Epoch 9/50\n",
      "10366/10366 [==============================] - 6s 568us/step - loss: 527.5505 - mean_absolute_error: 18.0793\n",
      "Epoch 10/50\n",
      "10366/10366 [==============================] - 6s 586us/step - loss: 512.1316 - mean_absolute_error: 17.7662\n",
      "Epoch 11/50\n",
      "10366/10366 [==============================] - 6s 582us/step - loss: 502.1879 - mean_absolute_error: 17.5529\n",
      "Epoch 12/50\n",
      "10366/10366 [==============================] - 6s 561us/step - loss: 494.9185 - mean_absolute_error: 17.4871\n",
      "Epoch 13/50\n",
      "10366/10366 [==============================] - 8s 765us/step - loss: 491.5204 - mean_absolute_error: 17.4265\n",
      "Epoch 14/50\n",
      "10366/10366 [==============================] - 7s 678us/step - loss: 486.5188 - mean_absolute_error: 17.2485\n",
      "Epoch 15/50\n",
      "10366/10366 [==============================] - 7s 691us/step - loss: 479.4181 - mean_absolute_error: 17.1407\n",
      "Epoch 16/50\n",
      "10366/10366 [==============================] - 6s 568us/step - loss: 482.8083 - mean_absolute_error: 17.1201\n",
      "Epoch 17/50\n",
      "10366/10366 [==============================] - 6s 571us/step - loss: 476.1643 - mean_absolute_error: 17.0546\n",
      "Epoch 18/50\n",
      "10366/10366 [==============================] - 6s 592us/step - loss: 470.0108 - mean_absolute_error: 16.9640\n",
      "Epoch 19/50\n",
      "10366/10366 [==============================] - 6s 588us/step - loss: 462.6710 - mean_absolute_error: 16.8122\n",
      "Epoch 20/50\n",
      "10366/10366 [==============================] - 8s 812us/step - loss: 458.9921 - mean_absolute_error: 16.8156\n",
      "Epoch 21/50\n",
      "10366/10366 [==============================] - 7s 675us/step - loss: 458.7340 - mean_absolute_error: 16.7467\n",
      "Epoch 22/50\n",
      "10366/10366 [==============================] - 6s 621us/step - loss: 460.1323 - mean_absolute_error: 16.7324\n",
      "Epoch 23/50\n",
      "10366/10366 [==============================] - 6s 587us/step - loss: 457.5054 - mean_absolute_error: 16.7001\n",
      "Epoch 24/50\n",
      "10366/10366 [==============================] - 8s 805us/step - loss: 452.2238 - mean_absolute_error: 16.5874\n",
      "Epoch 25/50\n",
      "10366/10366 [==============================] - 7s 668us/step - loss: 455.8937 - mean_absolute_error: 16.7327\n",
      "Epoch 26/50\n",
      "10366/10366 [==============================] - 7s 631us/step - loss: 447.3202 - mean_absolute_error: 16.5455\n",
      "Epoch 27/50\n",
      "10366/10366 [==============================] - 6s 583us/step - loss: 454.8207 - mean_absolute_error: 16.6365\n",
      "Epoch 28/50\n",
      "10366/10366 [==============================] - 9s 822us/step - loss: 445.6719 - mean_absolute_error: 16.5730\n",
      "Epoch 29/50\n",
      "10366/10366 [==============================] - 7s 691us/step - loss: 451.0582 - mean_absolute_error: 16.6848\n",
      "Epoch 30/50\n",
      "10366/10366 [==============================] - 7s 686us/step - loss: 444.5916 - mean_absolute_error: 16.4730\n",
      "Epoch 31/50\n",
      "10366/10366 [==============================] - 7s 681us/step - loss: 446.3251 - mean_absolute_error: 16.5833\n",
      "Epoch 32/50\n",
      "10366/10366 [==============================] - 7s 675us/step - loss: 442.4531 - mean_absolute_error: 16.4427\n",
      "Epoch 33/50\n",
      "10366/10366 [==============================] - 6s 571us/step - loss: 446.9176 - mean_absolute_error: 16.5962\n",
      "Epoch 34/50\n",
      "10366/10366 [==============================] - 8s 784us/step - loss: 434.6998 - mean_absolute_error: 16.3472\n",
      "Epoch 35/50\n",
      "10366/10366 [==============================] - 9s 834us/step - loss: 440.2033 - mean_absolute_error: 16.3920\n",
      "Epoch 36/50\n",
      "10366/10366 [==============================] - 7s 703us/step - loss: 440.5894 - mean_absolute_error: 16.4451\n",
      "Epoch 37/50\n",
      "10366/10366 [==============================] - 7s 695us/step - loss: 438.4711 - mean_absolute_error: 16.3532\n",
      "Epoch 38/50\n",
      "10366/10366 [==============================] - 7s 684us/step - loss: 438.7514 - mean_absolute_error: 16.4346\n",
      "Epoch 39/50\n",
      "10366/10366 [==============================] - 7s 709us/step - loss: 434.0092 - mean_absolute_error: 16.2954\n",
      "Epoch 40/50\n",
      "10366/10366 [==============================] - 10s 997us/step - loss: 439.0378 - mean_absolute_error: 16.4120\n",
      "Epoch 41/50\n",
      "10366/10366 [==============================] - 9s 884us/step - loss: 437.8696 - mean_absolute_error: 16.3440\n",
      "Epoch 42/50\n",
      "10366/10366 [==============================] - 7s 686us/step - loss: 442.6887 - mean_absolute_error: 16.4360\n",
      "Epoch 43/50\n",
      "10366/10366 [==============================] - 7s 711us/step - loss: 439.6297 - mean_absolute_error: 16.3805\n",
      "Epoch 44/50\n",
      "10366/10366 [==============================] - 10s 999us/step - loss: 432.1016 - mean_absolute_error: 16.2671\n",
      "Epoch 45/50\n",
      "10366/10366 [==============================] - 7s 719us/step - loss: 438.1015 - mean_absolute_error: 16.3424\n",
      "Epoch 46/50\n",
      "10366/10366 [==============================] - 8s 733us/step - loss: 433.7872 - mean_absolute_error: 16.2844\n",
      "Epoch 47/50\n",
      "10366/10366 [==============================] - 8s 742us/step - loss: 433.5816 - mean_absolute_error: 16.3464\n",
      "Epoch 48/50\n",
      "10366/10366 [==============================] - 9s 911us/step - loss: 426.9193 - mean_absolute_error: 16.1122\n",
      "Epoch 49/50\n",
      "10366/10366 [==============================] - 10s 920us/step - loss: 433.0676 - mean_absolute_error: 16.2573\n",
      "Epoch 50/50\n",
      "10366/10366 [==============================] - 7s 711us/step - loss: 434.8084 - mean_absolute_error: 16.3842\n",
      "QWK:  0.5027794924924422\n",
      "Fold # 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10371/10371 [==============================] - 10s 971us/step - loss: 3409.3579 - mean_absolute_error: 53.7608\n",
      "Epoch 2/50\n",
      "10371/10371 [==============================] - 8s 817us/step - loss: 2250.2770 - mean_absolute_error: 42.6317\n",
      "Epoch 3/50\n",
      "10371/10371 [==============================] - 7s 702us/step - loss: 1668.3725 - mean_absolute_error: 35.7504\n",
      "Epoch 4/50\n",
      "10371/10371 [==============================] - 6s 593us/step - loss: 1220.0839 - mean_absolute_error: 30.0926\n",
      "Epoch 5/50\n",
      "10371/10371 [==============================] - 6s 594us/step - loss: 895.3838 - mean_absolute_error: 25.3595\n",
      "Epoch 6/50\n",
      "10371/10371 [==============================] - 6s 607us/step - loss: 694.2617 - mean_absolute_error: 21.7718\n",
      "Epoch 7/50\n",
      "10371/10371 [==============================] - 6s 614us/step - loss: 578.3853 - mean_absolute_error: 19.3638\n",
      "Epoch 8/50\n",
      "10371/10371 [==============================] - 6s 607us/step - loss: 530.6583 - mean_absolute_error: 18.3028\n",
      "Epoch 9/50\n",
      "10371/10371 [==============================] - 6s 594us/step - loss: 518.2933 - mean_absolute_error: 17.9088\n",
      "Epoch 10/50\n",
      "10371/10371 [==============================] - 6s 604us/step - loss: 511.5245 - mean_absolute_error: 17.7972\n",
      "Epoch 11/50\n",
      "10371/10371 [==============================] - 6s 615us/step - loss: 504.0464 - mean_absolute_error: 17.6617\n",
      "Epoch 12/50\n",
      "10371/10371 [==============================] - 6s 616us/step - loss: 503.9717 - mean_absolute_error: 17.6551\n",
      "Epoch 13/50\n",
      "10371/10371 [==============================] - 6s 608us/step - loss: 492.6229 - mean_absolute_error: 17.4411\n",
      "Epoch 14/50\n",
      "10371/10371 [==============================] - 6s 605us/step - loss: 489.6572 - mean_absolute_error: 17.4471\n",
      "Epoch 15/50\n",
      "10371/10371 [==============================] - 6s 608us/step - loss: 477.6099 - mean_absolute_error: 17.1863\n",
      "Epoch 16/50\n",
      "10371/10371 [==============================] - 6s 621us/step - loss: 482.2565 - mean_absolute_error: 17.2222\n",
      "Epoch 17/50\n",
      "10371/10371 [==============================] - 6s 623us/step - loss: 473.0883 - mean_absolute_error: 17.1406\n",
      "Epoch 18/50\n",
      "10371/10371 [==============================] - 6s 606us/step - loss: 473.8068 - mean_absolute_error: 17.1279\n",
      "Epoch 19/50\n",
      "10371/10371 [==============================] - 6s 605us/step - loss: 467.5965 - mean_absolute_error: 16.8946\n",
      "Epoch 20/50\n",
      "10371/10371 [==============================] - 6s 614us/step - loss: 466.7021 - mean_absolute_error: 16.9444\n",
      "Epoch 21/50\n",
      "10371/10371 [==============================] - 6s 624us/step - loss: 452.2538 - mean_absolute_error: 16.7215\n",
      "Epoch 22/50\n",
      "10371/10371 [==============================] - 6s 531us/step - loss: 460.0186 - mean_absolute_error: 16.8347\n",
      "Epoch 23/50\n",
      "10371/10371 [==============================] - 6s 619us/step - loss: 457.7749 - mean_absolute_error: 16.7608\n",
      "Epoch 24/50\n",
      "10371/10371 [==============================] - 7s 692us/step - loss: 456.4057 - mean_absolute_error: 16.7968\n",
      "Epoch 25/50\n",
      "10371/10371 [==============================] - 6s 623us/step - loss: 455.4301 - mean_absolute_error: 16.6968\n",
      "Epoch 26/50\n",
      "10371/10371 [==============================] - 6s 617us/step - loss: 452.7504 - mean_absolute_error: 16.6719\n",
      "Epoch 27/50\n",
      "10371/10371 [==============================] - 9s 848us/step - loss: 453.8877 - mean_absolute_error: 16.7179\n",
      "Epoch 28/50\n",
      "10371/10371 [==============================] - 7s 670us/step - loss: 450.3519 - mean_absolute_error: 16.6759\n",
      "Epoch 29/50\n",
      "10371/10371 [==============================] - 7s 640us/step - loss: 449.1144 - mean_absolute_error: 16.6474\n",
      "Epoch 30/50\n",
      "10371/10371 [==============================] - 6s 620us/step - loss: 449.0557 - mean_absolute_error: 16.6334\n",
      "Epoch 31/50\n",
      "10371/10371 [==============================] - 9s 870us/step - loss: 449.9268 - mean_absolute_error: 16.6239\n",
      "Epoch 32/50\n",
      "10371/10371 [==============================] - 7s 657us/step - loss: 445.5996 - mean_absolute_error: 16.5316\n",
      "Epoch 33/50\n",
      "10371/10371 [==============================] - 7s 637us/step - loss: 448.6322 - mean_absolute_error: 16.6169\n",
      "Epoch 34/50\n",
      "10371/10371 [==============================] - 7s 635us/step - loss: 444.7851 - mean_absolute_error: 16.5142\n",
      "Epoch 35/50\n",
      "10371/10371 [==============================] - 9s 872us/step - loss: 440.9939 - mean_absolute_error: 16.4745\n",
      "Epoch 36/50\n",
      "10371/10371 [==============================] - 7s 637us/step - loss: 448.4255 - mean_absolute_error: 16.6086\n",
      "Epoch 37/50\n",
      "10371/10371 [==============================] - 5s 525us/step - loss: 446.2365 - mean_absolute_error: 16.5206\n",
      "Epoch 38/50\n",
      "10371/10371 [==============================] - 7s 686us/step - loss: 441.4833 - mean_absolute_error: 16.4681\n",
      "Epoch 39/50\n",
      "10371/10371 [==============================] - 7s 646us/step - loss: 436.3833 - mean_absolute_error: 16.3162\n",
      "Epoch 40/50\n",
      "10371/10371 [==============================] - 7s 722us/step - loss: 440.1276 - mean_absolute_error: 16.4310\n",
      "Epoch 41/50\n",
      "10371/10371 [==============================] - 9s 827us/step - loss: 437.2711 - mean_absolute_error: 16.4188\n",
      "Epoch 42/50\n",
      "10371/10371 [==============================] - 6s 605us/step - loss: 436.3928 - mean_absolute_error: 16.4319\n",
      "Epoch 43/50\n",
      "10371/10371 [==============================] - 6s 547us/step - loss: 440.4183 - mean_absolute_error: 16.4626\n",
      "Epoch 44/50\n",
      "10371/10371 [==============================] - 8s 732us/step - loss: 438.1253 - mean_absolute_error: 16.3548\n",
      "Epoch 45/50\n",
      "10371/10371 [==============================] - 7s 628us/step - loss: 442.2525 - mean_absolute_error: 16.4827\n",
      "Epoch 46/50\n",
      "10371/10371 [==============================] - 7s 640us/step - loss: 439.0748 - mean_absolute_error: 16.4108\n",
      "Epoch 47/50\n",
      "10371/10371 [==============================] - 7s 648us/step - loss: 441.8523 - mean_absolute_error: 16.4879\n",
      "Epoch 48/50\n",
      "10371/10371 [==============================] - 7s 642us/step - loss: 437.2607 - mean_absolute_error: 16.3976\n",
      "Epoch 49/50\n",
      "10371/10371 [==============================] - 7s 642us/step - loss: 436.6782 - mean_absolute_error: 16.3891\n",
      "Epoch 50/50\n",
      "10371/10371 [==============================] - 7s 640us/step - loss: 431.5916 - mean_absolute_error: 16.3180\n",
      "QWK:  0.5259217649877088\n",
      "Fold # 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10382/10382 [==============================] - 11s 1ms/step - loss: 3457.8697 - mean_absolute_error: 54.2930\n",
      "Epoch 2/50\n",
      "10382/10382 [==============================] - 10s 927us/step - loss: 2319.4129 - mean_absolute_error: 43.4109\n",
      "Epoch 3/50\n",
      "10382/10382 [==============================] - 10s 974us/step - loss: 1722.3385 - mean_absolute_error: 36.4623\n",
      "Epoch 4/50\n",
      "10382/10382 [==============================] - 9s 910us/step - loss: 1254.3586 - mean_absolute_error: 30.4962\n",
      "Epoch 5/50\n",
      "10382/10382 [==============================] - 8s 806us/step - loss: 919.3978 - mean_absolute_error: 25.7544\n",
      "Epoch 6/50\n",
      "10382/10382 [==============================] - 10s 925us/step - loss: 705.9882 - mean_absolute_error: 22.0927\n",
      "Epoch 7/50\n",
      "10382/10382 [==============================] - 10s 968us/step - loss: 622.7560 - mean_absolute_error: 20.1403\n",
      "Epoch 8/50\n",
      "10382/10382 [==============================] - 9s 824us/step - loss: 598.4145 - mean_absolute_error: 19.3592\n",
      "Epoch 9/50\n",
      "10382/10382 [==============================] - 8s 818us/step - loss: 553.4741 - mean_absolute_error: 18.6208\n",
      "Epoch 10/50\n",
      "10382/10382 [==============================] - 10s 966us/step - loss: 532.1335 - mean_absolute_error: 18.1822\n",
      "Epoch 11/50\n",
      "10382/10382 [==============================] - 9s 914us/step - loss: 514.1921 - mean_absolute_error: 17.8342\n",
      "Epoch 12/50\n",
      "10382/10382 [==============================] - 9s 895us/step - loss: 504.6423 - mean_absolute_error: 17.6168\n",
      "Epoch 13/50\n",
      "10382/10382 [==============================] - 11s 1ms/step - loss: 504.0730 - mean_absolute_error: 17.6310\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10382/10382 [==============================] - 8s 746us/step - loss: 491.9781 - mean_absolute_error: 17.4108\n",
      "Epoch 15/50\n",
      "10382/10382 [==============================] - 7s 637us/step - loss: 495.2169 - mean_absolute_error: 17.5310\n",
      "Epoch 16/50\n",
      "10382/10382 [==============================] - 6s 620us/step - loss: 484.6075 - mean_absolute_error: 17.2226\n",
      "Epoch 17/50\n",
      "10382/10382 [==============================] - 7s 638us/step - loss: 477.3882 - mean_absolute_error: 17.1436\n",
      "Epoch 18/50\n",
      "10382/10382 [==============================] - 7s 627us/step - loss: 478.6142 - mean_absolute_error: 17.1526\n",
      "Epoch 19/50\n",
      "10382/10382 [==============================] - 7s 644us/step - loss: 472.3414 - mean_absolute_error: 17.0138\n",
      "Epoch 20/50\n",
      "10382/10382 [==============================] - 7s 644us/step - loss: 465.2897 - mean_absolute_error: 16.8481\n",
      "Epoch 21/50\n",
      "10382/10382 [==============================] - 7s 645us/step - loss: 466.4608 - mean_absolute_error: 16.9048\n",
      "Epoch 22/50\n",
      "10382/10382 [==============================] - 7s 628us/step - loss: 451.8546 - mean_absolute_error: 16.6174\n",
      "Epoch 23/50\n",
      "10382/10382 [==============================] - 7s 630us/step - loss: 463.1646 - mean_absolute_error: 16.8817\n",
      "Epoch 24/50\n",
      "10382/10382 [==============================] - 9s 842us/step - loss: 446.8307 - mean_absolute_error: 16.5947\n",
      "Epoch 25/50\n",
      "10382/10382 [==============================] - 7s 722us/step - loss: 446.6005 - mean_absolute_error: 16.5553\n",
      "Epoch 26/50\n",
      "10382/10382 [==============================] - 7s 714us/step - loss: 447.0219 - mean_absolute_error: 16.5559\n",
      "Epoch 27/50\n",
      "10382/10382 [==============================] - 7s 672us/step - loss: 447.4105 - mean_absolute_error: 16.5011\n",
      "Epoch 28/50\n",
      "10382/10382 [==============================] - 7s 665us/step - loss: 438.5265 - mean_absolute_error: 16.3635\n",
      "Epoch 29/50\n",
      "10382/10382 [==============================] - 7s 653us/step - loss: 438.5077 - mean_absolute_error: 16.3644\n",
      "Epoch 30/50\n",
      "10382/10382 [==============================] - 7s 663us/step - loss: 439.7042 - mean_absolute_error: 16.3422\n",
      "Epoch 31/50\n",
      "10382/10382 [==============================] - 9s 856us/step - loss: 440.3905 - mean_absolute_error: 16.4289\n",
      "Epoch 32/50\n",
      "10382/10382 [==============================] - 8s 779us/step - loss: 439.1078 - mean_absolute_error: 16.3484\n",
      "Epoch 33/50\n",
      "10382/10382 [==============================] - 7s 682us/step - loss: 438.3986 - mean_absolute_error: 16.2835\n",
      "Epoch 34/50\n",
      "10382/10382 [==============================] - 7s 666us/step - loss: 444.4490 - mean_absolute_error: 16.4829\n",
      "Epoch 35/50\n",
      "10382/10382 [==============================] - 7s 648us/step - loss: 442.3232 - mean_absolute_error: 16.4894\n",
      "Epoch 36/50\n",
      "10382/10382 [==============================] - 7s 658us/step - loss: 437.8085 - mean_absolute_error: 16.3393\n",
      "Epoch 37/50\n",
      "10382/10382 [==============================] - 7s 661us/step - loss: 441.8356 - mean_absolute_error: 16.4415\n",
      "Epoch 38/50\n",
      "10382/10382 [==============================] - 7s 677us/step - loss: 438.7324 - mean_absolute_error: 16.3852\n",
      "Epoch 39/50\n",
      "10382/10382 [==============================] - 7s 710us/step - loss: 428.7926 - mean_absolute_error: 16.2322\n",
      "Epoch 40/50\n",
      "10382/10382 [==============================] - 8s 816us/step - loss: 435.3533 - mean_absolute_error: 16.3386\n",
      "Epoch 41/50\n",
      "10382/10382 [==============================] - 9s 912us/step - loss: 439.9774 - mean_absolute_error: 16.4485\n",
      "Epoch 42/50\n",
      "10382/10382 [==============================] - 9s 867us/step - loss: 435.1435 - mean_absolute_error: 16.3066\n",
      "Epoch 43/50\n",
      "10382/10382 [==============================] - 8s 784us/step - loss: 435.8022 - mean_absolute_error: 16.3234\n",
      "Epoch 44/50\n",
      "10382/10382 [==============================] - 8s 790us/step - loss: 430.0893 - mean_absolute_error: 16.2205\n",
      "Epoch 45/50\n",
      "10382/10382 [==============================] - 11s 1ms/step - loss: 434.3189 - mean_absolute_error: 16.3849\n",
      "Epoch 46/50\n",
      "10382/10382 [==============================] - 8s 757us/step - loss: 432.2551 - mean_absolute_error: 16.1570\n",
      "Epoch 47/50\n",
      "10382/10382 [==============================] - 11s 1ms/step - loss: 437.5147 - mean_absolute_error: 16.4131\n",
      "Epoch 48/50\n",
      "10382/10382 [==============================] - 9s 896us/step - loss: 431.1851 - mean_absolute_error: 16.2332\n",
      "Epoch 49/50\n",
      "10382/10382 [==============================] - 8s 758us/step - loss: 435.7692 - mean_absolute_error: 16.3145\n",
      "Epoch 50/50\n",
      "10382/10382 [==============================] - 11s 1ms/step - loss: 437.6128 - mean_absolute_error: 16.3422\n",
      "QWK:  0.4702928892754158\n",
      "Fold # 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10390/10390 [==============================] - 11s 1ms/step - loss: 3423.2045 - mean_absolute_error: 53.9243\n",
      "Epoch 2/50\n",
      "10390/10390 [==============================] - 8s 776us/step - loss: 2268.6646 - mean_absolute_error: 42.8238\n",
      "Epoch 3/50\n",
      "10390/10390 [==============================] - 8s 761us/step - loss: 1684.3797 - mean_absolute_error: 35.9344\n",
      "Epoch 4/50\n",
      "10390/10390 [==============================] - 8s 792us/step - loss: 1222.0897 - mean_absolute_error: 30.0561\n",
      "Epoch 5/50\n",
      "10390/10390 [==============================] - 9s 902us/step - loss: 899.0576 - mean_absolute_error: 25.4210\n",
      "Epoch 6/50\n",
      "10390/10390 [==============================] - 10s 976us/step - loss: 700.6643 - mean_absolute_error: 21.9016\n",
      "Epoch 7/50\n",
      "10390/10390 [==============================] - 8s 815us/step - loss: 602.1894 - mean_absolute_error: 19.7770\n",
      "Epoch 8/50\n",
      "10390/10390 [==============================] - 11s 1ms/step - loss: 545.5883 - mean_absolute_error: 18.5082\n",
      "Epoch 9/50\n",
      "10390/10390 [==============================] - 8s 807us/step - loss: 527.5124 - mean_absolute_error: 18.0648\n",
      "Epoch 10/50\n",
      "10390/10390 [==============================] - 11s 1ms/step - loss: 513.6270 - mean_absolute_error: 17.8256\n",
      "Epoch 11/50\n",
      "10390/10390 [==============================] - 10s 1ms/step - loss: 502.1374 - mean_absolute_error: 17.6412\n",
      "Epoch 12/50\n",
      "10390/10390 [==============================] - 11s 1ms/step - loss: 501.2068 - mean_absolute_error: 17.5506\n",
      "Epoch 13/50\n",
      "10390/10390 [==============================] - 8s 799us/step - loss: 486.7215 - mean_absolute_error: 17.3164\n",
      "Epoch 14/50\n",
      "10390/10390 [==============================] - 11s 1ms/step - loss: 499.8730 - mean_absolute_error: 17.5991\n",
      "Epoch 15/50\n",
      "10390/10390 [==============================] - 10s 918us/step - loss: 488.0559 - mean_absolute_error: 17.3507\n",
      "Epoch 16/50\n",
      "10390/10390 [==============================] - 9s 846us/step - loss: 477.0858 - mean_absolute_error: 17.0909\n",
      "Epoch 17/50\n",
      "10390/10390 [==============================] - 9s 838us/step - loss: 481.6705 - mean_absolute_error: 17.1841\n",
      "Epoch 18/50\n",
      "10390/10390 [==============================] - 11s 1ms/step - loss: 472.8698 - mean_absolute_error: 17.0391\n",
      "Epoch 19/50\n",
      "10390/10390 [==============================] - 9s 841us/step - loss: 465.5537 - mean_absolute_error: 16.8833\n",
      "Epoch 20/50\n",
      "10390/10390 [==============================] - 13s 1ms/step - loss: 464.0964 - mean_absolute_error: 16.8820\n",
      "Epoch 21/50\n",
      "10390/10390 [==============================] - 8s 797us/step - loss: 461.2979 - mean_absolute_error: 16.8498\n",
      "Epoch 22/50\n",
      "10390/10390 [==============================] - 11s 1ms/step - loss: 457.9663 - mean_absolute_error: 16.7103 0s - loss: 457.4978 - mean_absol\n",
      "Epoch 23/50\n",
      "10390/10390 [==============================] - 8s 803us/step - loss: 455.9179 - mean_absolute_error: 16.6944\n",
      "Epoch 24/50\n",
      "10390/10390 [==============================] - 6s 619us/step - loss: 453.7018 - mean_absolute_error: 16.7556\n",
      "Epoch 25/50\n",
      "10390/10390 [==============================] - 6s 615us/step - loss: 451.0210 - mean_absolute_error: 16.6267\n",
      "Epoch 26/50\n",
      "10390/10390 [==============================] - 6s 606us/step - loss: 452.3621 - mean_absolute_error: 16.6734\n",
      "Epoch 27/50\n",
      "10390/10390 [==============================] - 6s 599us/step - loss: 458.3143 - mean_absolute_error: 16.8146\n",
      "Epoch 28/50\n",
      "10390/10390 [==============================] - 6s 613us/step - loss: 451.2198 - mean_absolute_error: 16.7297\n",
      "Epoch 29/50\n",
      "10390/10390 [==============================] - 6s 615us/step - loss: 450.5981 - mean_absolute_error: 16.6281\n",
      "Epoch 30/50\n",
      "10390/10390 [==============================] - 6s 621us/step - loss: 447.7471 - mean_absolute_error: 16.5508\n",
      "Epoch 31/50\n",
      "10390/10390 [==============================] - 6s 602us/step - loss: 447.9422 - mean_absolute_error: 16.4879\n",
      "Epoch 32/50\n",
      "10390/10390 [==============================] - 6s 603us/step - loss: 445.4306 - mean_absolute_error: 16.6017\n",
      "Epoch 33/50\n",
      "10390/10390 [==============================] - 6s 615us/step - loss: 443.3916 - mean_absolute_error: 16.4285\n",
      "Epoch 34/50\n",
      "10390/10390 [==============================] - 6s 619us/step - loss: 446.6619 - mean_absolute_error: 16.6105\n",
      "Epoch 35/50\n",
      "10390/10390 [==============================] - 6s 620us/step - loss: 445.7633 - mean_absolute_error: 16.5378\n",
      "Epoch 36/50\n",
      "10390/10390 [==============================] - 6s 607us/step - loss: 444.9813 - mean_absolute_error: 16.5515\n",
      "Epoch 37/50\n",
      "10390/10390 [==============================] - 6s 616us/step - loss: 440.4685 - mean_absolute_error: 16.4426\n",
      "Epoch 38/50\n",
      "10390/10390 [==============================] - 6s 623us/step - loss: 446.9470 - mean_absolute_error: 16.5549\n",
      "Epoch 39/50\n",
      "10390/10390 [==============================] - 7s 628us/step - loss: 442.4566 - mean_absolute_error: 16.4780\n",
      "Epoch 40/50\n",
      "10390/10390 [==============================] - 7s 630us/step - loss: 444.5945 - mean_absolute_error: 16.5151\n",
      "Epoch 41/50\n",
      "10390/10390 [==============================] - 6s 610us/step - loss: 439.2658 - mean_absolute_error: 16.4388\n",
      "Epoch 42/50\n",
      "10390/10390 [==============================] - 9s 861us/step - loss: 435.0634 - mean_absolute_error: 16.3153\n",
      "Epoch 43/50\n",
      "10390/10390 [==============================] - 7s 651us/step - loss: 432.8638 - mean_absolute_error: 16.3188\n",
      "Epoch 44/50\n",
      "10390/10390 [==============================] - 7s 682us/step - loss: 432.9405 - mean_absolute_error: 16.3483\n",
      "Epoch 45/50\n",
      "10390/10390 [==============================] - 9s 838us/step - loss: 435.3787 - mean_absolute_error: 16.3410\n",
      "Epoch 46/50\n",
      "10390/10390 [==============================] - 6s 620us/step - loss: 432.6225 - mean_absolute_error: 16.3644\n",
      "Epoch 47/50\n",
      "10390/10390 [==============================] - 7s 634us/step - loss: 436.9328 - mean_absolute_error: 16.3743\n",
      "Epoch 48/50\n",
      "10390/10390 [==============================] - 7s 641us/step - loss: 435.0956 - mean_absolute_error: 16.2906\n",
      "Epoch 49/50\n",
      "10390/10390 [==============================] - 7s 638us/step - loss: 429.6428 - mean_absolute_error: 16.2428\n",
      "Epoch 50/50\n",
      "10390/10390 [==============================] - 7s 631us/step - loss: 425.9823 - mean_absolute_error: 16.1510\n",
      "QWK:  0.5233945083022886\n",
      "Fold # 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10403/10403 [==============================] - 9s 888us/step - loss: 3435.6809 - mean_absolute_error: 54.0209\n",
      "Epoch 2/50\n",
      "10403/10403 [==============================] - 6s 586us/step - loss: 2287.4295 - mean_absolute_error: 43.0257\n",
      "Epoch 3/50\n",
      "10403/10403 [==============================] - 8s 751us/step - loss: 1699.4623 - mean_absolute_error: 36.1423\n",
      "Epoch 4/50\n",
      "10403/10403 [==============================] - 7s 647us/step - loss: 1241.0996 - mean_absolute_error: 30.3522\n",
      "Epoch 5/50\n",
      "10403/10403 [==============================] - 7s 640us/step - loss: 904.7786 - mean_absolute_error: 25.4899\n",
      "Epoch 6/50\n",
      "10403/10403 [==============================] - 7s 640us/step - loss: 702.7400 - mean_absolute_error: 21.9672\n",
      "Epoch 7/50\n",
      "10403/10403 [==============================] - 7s 646us/step - loss: 612.8122 - mean_absolute_error: 19.8806\n",
      "Epoch 8/50\n",
      "10403/10403 [==============================] - 8s 784us/step - loss: 593.0174 - mean_absolute_error: 19.2126\n",
      "Epoch 9/50\n",
      "10403/10403 [==============================] - 9s 868us/step - loss: 550.4683 - mean_absolute_error: 18.6164\n",
      "Epoch 10/50\n",
      "10403/10403 [==============================] - 7s 655us/step - loss: 523.9736 - mean_absolute_error: 18.0226\n",
      "Epoch 11/50\n",
      "10403/10403 [==============================] - 9s 884us/step - loss: 519.0315 - mean_absolute_error: 17.9565\n",
      "Epoch 12/50\n",
      "10403/10403 [==============================] - 7s 661us/step - loss: 503.0596 - mean_absolute_error: 17.5739\n",
      "Epoch 13/50\n",
      "10403/10403 [==============================] - 7s 669us/step - loss: 502.9997 - mean_absolute_error: 17.6300\n",
      "Epoch 14/50\n",
      "10403/10403 [==============================] - 7s 630us/step - loss: 493.2371 - mean_absolute_error: 17.4132\n",
      "Epoch 15/50\n",
      "10403/10403 [==============================] - 6s 555us/step - loss: 488.8160 - mean_absolute_error: 17.3992\n",
      "Epoch 16/50\n",
      "10403/10403 [==============================] - 6s 558us/step - loss: 487.2480 - mean_absolute_error: 17.2766\n",
      "Epoch 17/50\n",
      "10403/10403 [==============================] - 7s 700us/step - loss: 481.8141 - mean_absolute_error: 17.3058\n",
      "Epoch 18/50\n",
      "10403/10403 [==============================] - 8s 754us/step - loss: 475.4649 - mean_absolute_error: 17.1090\n",
      "Epoch 19/50\n",
      "10403/10403 [==============================] - 8s 736us/step - loss: 474.3365 - mean_absolute_error: 17.0433\n",
      "Epoch 20/50\n",
      "10403/10403 [==============================] - 9s 904us/step - loss: 467.9872 - mean_absolute_error: 16.9420\n",
      "Epoch 21/50\n",
      "10403/10403 [==============================] - 8s 810us/step - loss: 463.5673 - mean_absolute_error: 16.8596\n",
      "Epoch 22/50\n",
      "10403/10403 [==============================] - 9s 833us/step - loss: 458.5735 - mean_absolute_error: 16.7636\n",
      "Epoch 23/50\n",
      "10403/10403 [==============================] - 8s 731us/step - loss: 454.0764 - mean_absolute_error: 16.7343\n",
      "Epoch 24/50\n",
      "10403/10403 [==============================] - 7s 697us/step - loss: 454.0630 - mean_absolute_error: 16.7117\n",
      "Epoch 25/50\n",
      "10403/10403 [==============================] - 7s 704us/step - loss: 445.1273 - mean_absolute_error: 16.4898\n",
      "Epoch 26/50\n",
      "10403/10403 [==============================] - 6s 581us/step - loss: 446.8729 - mean_absolute_error: 16.5215\n",
      "Epoch 27/50\n",
      "10403/10403 [==============================] - 8s 781us/step - loss: 447.0171 - mean_absolute_error: 16.5638\n",
      "Epoch 28/50\n",
      "10403/10403 [==============================] - 7s 665us/step - loss: 447.5403 - mean_absolute_error: 16.5826\n",
      "Epoch 29/50\n",
      "10403/10403 [==============================] - 6s 609us/step - loss: 441.7483 - mean_absolute_error: 16.4523\n",
      "Epoch 30/50\n",
      "10403/10403 [==============================] - 7s 640us/step - loss: 448.8950 - mean_absolute_error: 16.5574\n",
      "Epoch 31/50\n",
      "10403/10403 [==============================] - 6s 565us/step - loss: 442.8844 - mean_absolute_error: 16.4761\n",
      "Epoch 32/50\n",
      "10403/10403 [==============================] - 6s 562us/step - loss: 440.0665 - mean_absolute_error: 16.4435\n",
      "Epoch 33/50\n",
      "10403/10403 [==============================] - 6s 556us/step - loss: 442.7509 - mean_absolute_error: 16.4979\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10403/10403 [==============================] - 6s 577us/step - loss: 448.6857 - mean_absolute_error: 16.5388\n",
      "Epoch 35/50\n",
      "10403/10403 [==============================] - 6s 573us/step - loss: 438.5300 - mean_absolute_error: 16.4083\n",
      "Epoch 36/50\n",
      "10403/10403 [==============================] - 6s 575us/step - loss: 445.6551 - mean_absolute_error: 16.4975\n",
      "Epoch 37/50\n",
      "10403/10403 [==============================] - 6s 565us/step - loss: 436.6480 - mean_absolute_error: 16.3973\n",
      "Epoch 38/50\n",
      "10403/10403 [==============================] - 6s 553us/step - loss: 438.2243 - mean_absolute_error: 16.3851\n",
      "Epoch 39/50\n",
      "10403/10403 [==============================] - 5s 503us/step - loss: 436.5310 - mean_absolute_error: 16.3538\n",
      "Epoch 40/50\n",
      "10403/10403 [==============================] - 8s 763us/step - loss: 441.1363 - mean_absolute_error: 16.41971s - loss: 442.982\n",
      "Epoch 41/50\n",
      "10403/10403 [==============================] - 11s 1ms/step - loss: 435.4788 - mean_absolute_error: 16.3556\n",
      "Epoch 42/50\n",
      "10403/10403 [==============================] - 8s 805us/step - loss: 434.0569 - mean_absolute_error: 16.2984\n",
      "Epoch 43/50\n",
      "10403/10403 [==============================] - 8s 803us/step - loss: 437.8644 - mean_absolute_error: 16.3877\n",
      "Epoch 44/50\n",
      "10403/10403 [==============================] - 10s 1ms/step - loss: 442.3954 - mean_absolute_error: 16.4644\n",
      "Epoch 45/50\n",
      "10403/10403 [==============================] - 10s 988us/step - loss: 437.1224 - mean_absolute_error: 16.3291\n",
      "Epoch 46/50\n",
      "10403/10403 [==============================] - 10s 922us/step - loss: 430.0587 - mean_absolute_error: 16.2359\n",
      "Epoch 47/50\n",
      "10403/10403 [==============================] - 13s 1ms/step - loss: 435.5805 - mean_absolute_error: 16.3111\n",
      "Epoch 48/50\n",
      "10403/10403 [==============================] - 10s 935us/step - loss: 439.5073 - mean_absolute_error: 16.3961\n",
      "Epoch 49/50\n",
      "10403/10403 [==============================] - 7s 689us/step - loss: 426.8190 - mean_absolute_error: 16.1730\n",
      "Epoch 50/50\n",
      "10403/10403 [==============================] - 7s 676us/step - loss: 429.8586 - mean_absolute_error: 16.2595\n",
      "QWK:  0.48561460974355874\n",
      "Average Quadratic Weighted Kappa after 5-fold cross validation for average word2vec  0.5016\n"
     ]
    }
   ],
   "source": [
    "dataset = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "dataset = dataset.split(X, y)\n",
    "results_average = train_model(X, y, dataset, \"average\")\n",
    "print(\"Average Quadratic Weighted Kappa after 5-fold cross validation for average word2vec \",np.around(np.array(results_average).mean(),decimals=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
